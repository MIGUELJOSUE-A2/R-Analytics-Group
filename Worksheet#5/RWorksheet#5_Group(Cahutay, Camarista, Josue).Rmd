---
title: "RWorksheet#5_Group(Cahutay, Camarista, Josue)"
author: "Cahutay, Camarista, Josue"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(polite)
library(httr)
library(rvest)
library(dplyr)
url <- "https://www.imdb.com/chart/toptv/?sort=rank%2Casc"

session <- bow(url, 
               user_agent = "Educational")
session
```

1. Extracting TV Shows
```{r}
#Extracting the ranks and titles
title_list <- read_html(url) %>%
  html_nodes('.ipc-title__text') %>%
  html_text()
title_list
```

```{r}
#Cleaning extracted text
title_list_sub <- as.data.frame(title_list[3:27], stringsAsFactors = FALSE)
colnames(title_list_sub) <- "ranks"

split_df <- strsplit(as.character(title_list_sub$ranks), "\\.", fixed = FALSE)
split_df <- data.frame(do.call(rbind, split_df), stringsAsFactors = FALSE)

colnames(split_df) <- c("rank", "title")
split_df <- split_df %>% select(rank, title)

split_df$title <- trimws(split_df$title)

rank_title <- split_df
rank_title
```

```{r} 
#Extracting tv rating, the number of people who voted, the number of episodes, and the year it was released.
rating_ls <- read_html(url) %>%
  html_nodes('.ipc-rating-star--rating') %>%
  html_text()

voter_ls <- read_html(url) %>%
  html_nodes('.ipc-rating-star--voteCount') %>%
  html_text()
clean_votes <- gsub('[()]', '', voter_ls)

#extracted the number of episodes
eps_ls <- read_html(url) %>%
  html_nodes('span.exckou.cli-title-metadata-item:nth-of-type(2)') %>%
  html_text()
clean_eps <- gsub('[eps]', '', eps_ls)
num_eps <- as.numeric(clean_eps)
#note to self, use gsub() to remove constant strings appearing in the dataset.

#extracted the year released 
years <- read_html(url) %>%
  html_nodes('span.exckou.cli-title-metadata-item:nth-of-type(1)') %>%
  html_text()
```

```{r}
top_tv_shows <- data.frame(
  Rank = rank_title[,1],
  Title = rank_title[,2],
  Rating = rating_ls,
  Voters = clean_votes,
  Episodes = num_eps,
  Year = years
)
top_tv_shows
```

Number of user reviews
```{r}
home_link <- 'https://www.imdb.com/chart/toptv/'
main_page <- read_html(home_link)

links <- main_page %>%
  html_nodes("a.ipc-title-link-wrapper") %>%
  html_attr("href")

# Loop to get link of each show's page
show_data <- lapply(links, function(link) {
  complete_link <- paste0("https://imdb.com", link)
  
  #loop to get the link for user review page
  usrv_link <- read_html(complete_link)
  usrv_link_page <- usrv_link %>%
    html_nodes('a.isReview') %>%
    html_attr("href")
  
  #loop to get user reviews of each shows
  usrv <- read_html(paste0("https://imdb.com", usrv_link_page[1]))
  usrv_count <- usrv %>%
    html_nodes('[data-testid="tturv-total-reviews"]') %>%
    html_text()
  
  #loop to extract critic reviews
  critic <- usrv_link %>%
              html_nodes("span.score") %>%
              html_text()
  critic_df <- data.frame(Critic_Reviews = critic[2], stringsAsFactors = FALSE)
  
  #loop to extract pop rating
  pop_rating <- usrv_link %>%
              html_nodes('[data-testid="hero-rating-bar__popularity__score"]') %>%
              html_text()
  pop_rating_df <- data.frame(Popularity_Rating = pop_rating[2], stringsAsFactors = FALSE)
  
  return(data.frame(User_Reviews = usrv_count, Critic = critic_df, pop = pop_rating_df)) 
})

show_url_df <- do.call(rbind, show_data)
shows <- cbind(top_tv_shows, show_url_df)
shows
```


2. 5 tv shows to scrape 20 user reviews.
```{r}
#links of the 5 shows I want to scrape
#breaking bad, planet earth 2, band of brothers, chernobyl, game of thrones 
library(rvest)
library(dplyr)

url_of_5Shows <- c(
  "https://www.imdb.com/title/tt0903747/reviews/?ref_=ttexr_ql_2",
  "https://www.imdb.com/title/tt5491994/reviews/?ref_=tt_ov_ql_2",
  "https://www.imdb.com/title/tt0185906/reviews/?ref_=tt_ov_ql_2",
  "https://www.imdb.com/title/tt7366338/reviews/?ref_=tt_ov_ql_2",
  "https://www.imdb.com/title/tt0944947/reviews/?ref_=tt_ov_ql_2"
)

five_shows_url_df <- data.frame(
  Title = c(
    "Breaking Bad",
    "Planet Earth II",
    "Band of Brothers",
    "Chernobyl", 
    "Game of Thrones"
  ),
  URLs = url_of_5Shows
) 

#function for scraping reviews
scrape_reviews <- function(show_url) {
  page <- read_html(show_url)
  
  # scrape usernames
  usernames <- page %>%
    html_nodes('[data-testid="author-link"]') %>%
    html_text()
  
  # scrape review dates
  review_dates <- page %>%
    html_nodes('li.review-date') %>%
    html_text()
  
  #scrape user rating
  user_rating <- page %>%
    html_nodes('span.ipc-rating-star--rating') %>%
    html_text()
  
  #scrape user's review title
  rev_title <- page %>%
    html_nodes('h3.ipc-title__text') %>%
    html_text()
  
  #scrape user text reviews
  text_rev <- page %>%
    html_nodes('div.ipc-html-content-inner-div') %>%
    html_text()
  
  #two codeblocks below are still being fixed
  #scrape helpful reviews
  helpful_rev <- page %>%
    html_nodes('div.ipc-list-card__actions') %>%
    html_text()
  
  #scrape not helpful reviews
  not_helpful <- page %>%
    html_nodes('span.count--down') %>%
    html_text()
  
  data.frame(
    Usernames = head(usernames, 20), 
    Dates = head(review_dates, 20),
    User_Rating = head(user_rating, 20), 
    Review_Title = head(rev_title, 20),
    Text_Reviews = head(text_rev, 20)
    )
}

reviews_data <- lapply(five_shows_url_df$URLs, scrape_reviews)
names(reviews_data) <- five_shows_url_df$Title
reviews_data[["Breaking Bad"]]
reviews_data[["Planet Earth II"]]
reviews_data[["Band of Brothers"]]
reviews_data[["Chernobyl"]]
reviews_data[["Game of Thrones"]]
```

3. Time series for tv shows released by year and the most number of tv
shows released.
```{r}
library(ggplot2)
years <- substr(years, 1,4)
years <- as.numeric(years)      

ggplot(data.frame(Year = years), aes(x = Year)) +
  geom_line(stat = "count", fill = "skyblue", color = "blue") +
  labs(title = "Number of TV Shows Released by Year",
       x = "Year",
       y = "Number of TV Shows") +
  theme_minimal()

most_shows_year <- as.data.frame(table(years))
most_shows_year <- most_shows_year[which.max(most_shows_year$Freq), ]
print(most_shows_year)

```

```{r}
# Load necessary libraries
library(rvest)
library(httr)
library(dplyr)
library(polite)
library(stringr)


url <- "https://www.amazon.com/"
session <- bow(url, 
               user_agent = "Educational")
session

# Define URLs
urls <- c('https://www.amazon.com/s?k=backpacks&crid=35ZQ1H72MC3G9&sprefix=backpacks%2Caps%2C590&ref=nb_sb_ss_ts-doa-p_3_9', 
          'https://www.amazon.com/s?k=laptops&crid=L7MQBW7MD4SX&sprefix=laptopb%2Caps%2C1304&ref=nb_sb_noss_2',
          'https://www.amazon.com/s?k=phone+case&dc&crid=1VPDCJ87S93TL&sprefix=phone+cas%2Caps%2C451&ref=a9_asc_1',
          'https://www.amazon.com/s?k=mountain+bike&crid=1ZQR71S8XHZN6&sprefix=mountain+bik%2Caps%2C499&ref=nb_sb_noss_2',
          'https://www.amazon.com/s?k=tshirt&crid=2RQIP7MP6IYAW&sprefix=tshirt%2Caps%2C443&ref=nb_sb_noss_2')

category_df <- data.frame(
  URL = urls,
  Category = c(
    "Backpacks",
    "Laptops",
    "Accessories",
    "Sports",
    "Clothing"
  )
)
```


```{r}
amazon_products <- function(url) {
  page <- read_html(url)
  
  name <- page %>%
    html_nodes("h2.a-size-mini") %>%
    html_text() 
  
  price <- page %>%
    html_nodes("span.a-price-whole") %>%
    html_text() %>%
    gsub("\\.", "", .)
  
  ratings <- page %>%
    html_nodes("span.a-icon-alt") %>%
    html_text() %>%
    gsub(" out of 5 stars", "", .) %>%
    gsub(" Stars & Up", "", .)
  
  prod_link <- page %>%
    html_nodes("a.a-link-normal.s-underline-text.s-underline-link-text.s-link-style.a-text-normal") %>%
    html_attr("href") %>%
    paste0("https://www.amazon.com", .)
  
  data.frame(
    Name = name[1:30],
    Price = price[1:30],
    Ratings = ratings[1:30],
    link = prod_link[1:30]
  )
}

products <- lapply(urls, amazon_products)
names(products) <- category_df$Category
products[["Backpacks"]]
products[["Laptops"]]
products[["Accessories"]]
products[["Sports"]]
products[["Clothing"]]
```
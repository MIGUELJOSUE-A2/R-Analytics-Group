---
title: "RWorksheet#5_Group(Cahutay, Camarista, Josue)"
author: "Cahutay, Camarista, Josue"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(polite)
library(httr)
library(rvest)
library(dplyr)
url <- "https://www.imdb.com/chart/toptv/?sort=rank%2Casc"

session <- bow(url, 
               user_agent = "Educational")
session
```

1. Extracting TV Shows
```{r}
#Extracting the ranks and titles
title_list <- read_html(url) %>%
  html_nodes('.ipc-title__text') %>%
  html_text()
```

```{r}
#Cleaning extracted text
title_list_sub <- as.data.frame(title_list[3:27], stringsAsFactors = FALSE)
colnames(title_list_sub) <- "ranks"

split_df <- strsplit(as.character(title_list_sub$ranks), "\\.", fixed = FALSE)
split_df <- data.frame(do.call(rbind, split_df), stringsAsFactors = FALSE)

colnames(split_df) <- c("rank", "title")
split_df <- split_df %>% select(rank, title)

split_df$title <- trimws(split_df$title)

rank_title <- split_df
rank_title
```

```{r} 
#Extracting tv rating, the number of people who voted, the number of episodes, and the year it was released.
rating_ls <- read_html(url) %>%
  html_nodes('.ipc-rating-star--rating') %>%
  html_text()

voter_ls <- read_html(url) %>%
  html_nodes('.ipc-rating-star--voteCount') %>%
  html_text()
clean_votes <- gsub('[()]', '', voter_ls)

#extracted the number of episodes
eps_ls <- read_html(url) %>%
  html_nodes('span.sc-300a8231-7.eaXxft.cli-title-metadata-item:nth-of-type(2)') %>%
  html_text()
clean_eps <- gsub('[eps]', '', eps_ls)
num_eps <- as.numeric(clean_eps)
#note to self, use gsub() to remove constant strings appearing in the dataset.

#extracted the year released 
years <- read_html(url) %>%
  html_nodes('span.sc-300a8231-7.eaXxft.cli-title-metadata-item:nth-of-type(1)') %>%
  html_text()
```

```{r}
top_tv_shows <- data.frame(
  Rank = rank_title[,1],
  Title = rank_title[,2],
  Rating = rating_ls,
  Voters = clean_votes,
  Episodes = num_eps,
  Year = years
)
top_tv_shows
#displays the data frame of top tv shows, with their Rank, Title, Rating, Number of Voters, Episodes, and Year released
```

Number of user reviews
```{r}
home_link <- 'https://www.imdb.com/chart/toptv/'
main_page <- read_html(home_link)

links <- main_page %>%
  html_nodes("a.ipc-title-link-wrapper") %>%
  html_attr("href")

# Loop to get link of each show's page
show_data <- lapply(links, function(link) {
  complete_link <- paste0("https://imdb.com", link)
  
  #loop to get the link for user review page
  usrv_link <- read_html(complete_link)
  usrv_link_page <- usrv_link %>%
    html_nodes('a.isReview') %>%
    html_attr("href")
  
  #loop to get user reviews of each shows
  usrv <- read_html(paste0("https://imdb.com", usrv_link_page[1]))
  usrv_count <- usrv %>%
    html_nodes('[data-testid="tturv-total-reviews"]') %>%
    html_text()
  
  #loop to extract critic reviews
  critic <- usrv_link %>%
              html_nodes("span.score") %>%
              html_text()
  critic_df <- data.frame(Critic_Reviews = critic[2], stringsAsFactors = FALSE)
  
  #loop to extract pop rating
  pop_rating <- usrv_link %>%
              html_nodes('[data-testid="hero-rating-bar__popularity__score"]') %>%
              html_text()
  pop_rating_df <- data.frame(Popularity_Rating = pop_rating[2], stringsAsFactors = FALSE)
  
  return(data.frame(User_Reviews = usrv_count, Critic = critic_df, pop = pop_rating_df)) 
})

show_url_df <- do.call(rbind, show_data)
shows <- cbind(top_tv_shows, show_url_df)
shows
#shows df with user reviews, critic reviews, and popularity ratings.
```

2. 5 tv shows to scrape 20 user reviews.
```{r}
#links of the 5 shows I want to scrape
#breaking bad, planet earth 2, band of brothers, chernobyl, game of thrones 
library(rvest)
library(dplyr)

url_of_5Shows <- c(
  "https://www.imdb.com/title/tt0903747/reviews/?ref_=ttexr_ql_2",
  "https://www.imdb.com/title/tt5491994/reviews/?ref_=tt_ov_ql_2",
  "https://www.imdb.com/title/tt0185906/reviews/?ref_=tt_ov_ql_2",
  "https://www.imdb.com/title/tt7366338/reviews/?ref_=tt_ov_ql_2",
  "https://www.imdb.com/title/tt0944947/reviews/?ref_=tt_ov_ql_2"
)

five_shows_url_df <- data.frame(
  Title = c(
    "Breaking Bad",
    "Planet Earth II",
    "Band of Brothers",
    "Chernobyl", 
    "Game of Thrones"
  ),
  URLs = url_of_5Shows
) 

#function for scraping reviews
scrape_reviews <- function(show_url) {
  page <- read_html(show_url)
  
  # scrape usernames
  usernames <- page %>%
    html_nodes('[data-testid="author-link"]') %>%
    html_text()
  
  # scrape review dates
  review_dates <- page %>%
    html_nodes('li.review-date') %>%
    html_text()
  
  #scrape user rating
  user_rating <- page %>%
    html_nodes('span.ipc-rating-star--rating') %>%
    html_text()
  
  #scrape user's review title
  rev_title <- page %>%
    html_nodes('h3.ipc-title__text') %>%
    html_text()
  
  #scrape user text reviews
  text_rev <- page %>%
    html_nodes('div.ipc-html-content-inner-div') %>%
    html_text()
  
  #two codeblocks below are still being fixed
  #scrape helpful reviews
  helpful_rev <- page %>%
    html_nodes('div.ipc-list-card__actions') %>%
    html_text()
  
  #scrape not helpful reviews
  not_helpful <- page %>%
    html_nodes('span.count--down') %>%
    html_text()
  
  data.frame(
    Usernames = head(usernames, 20), 
    Dates = head(review_dates, 20),
    User_Rating = head(user_rating, 20), 
    Review_Title = head(rev_title, 20),
    Text_Reviews = head(text_rev, 20)
    )
}

reviews_data <- lapply(five_shows_url_df$URLs, scrape_reviews)
names(reviews_data) <- five_shows_url_df$Title
reviews_data[["Breaking Bad"]]
reviews_data[["Planet Earth II"]]
reviews_data[["Band of Brothers"]]
reviews_data[["Chernobyl"]]
reviews_data[["Game of Thrones"]]
```

3. Time series for tv shows released by year and the most number of tv
shows released.
```{r}
library(ggplot2)
years <- substr(years, 1,4)
years <- as.numeric(years)      

ggplot(data.frame(Year = years), aes(x = Year)) +
  geom_line(stat = "count", fill = "skyblue", color = "blue") +
  labs(title = "Number of TV Shows Released by Year",
       x = "Year",
       y = "Number of TV Shows") +
  theme_minimal()

most_shows_year <- as.data.frame(table(years))
most_shows_year <- most_shows_year[which.max(most_shows_year$Freq), ]
print(most_shows_year)
```

4. Select 5 categories from Amazon and select 30 products from each category.
```{r}
# Load necessary libraries
library(rvest)
library(httr)
library(dplyr)
library(polite)
library(stringr)

url <- "https://www.amazon.com/"
session <- bow(url, 
               user_agent = "Educational")
session

# Define URLs
urls <- c('https://www.amazon.com/s?k=backpacks&crid=35ZQ1H72MC3G9&sprefix=backpacks%2Caps%2C590&ref=nb_sb_ss_ts-doa-p_3_9', 
          'https://www.amazon.com/s?k=laptops&crid=L7MQBW7MD4SX&sprefix=laptopb%2Caps%2C1304&ref=nb_sb_noss_2',
          'https://www.amazon.com/s?k=phone+case&dc&crid=1VPDCJ87S93TL&sprefix=phone+cas%2Caps%2C451&ref=a9_asc_1',
          'https://www.amazon.com/s?k=mountain+bike&crid=1ZQR71S8XHZN6&sprefix=mountain+bik%2Caps%2C499&ref=nb_sb_noss_2',
          'https://www.amazon.com/s?k=tshirt&crid=2RQIP7MP6IYAW&sprefix=tshirt%2Caps%2C443&ref=nb_sb_noss_2')

category_df <- data.frame(
  URL = urls,
  Category = c(
    "Backpacks",
    "Laptops",
    "Accessories",
    "Sports",
    "Clothing"
  )
)
```

5. Extract the price, description, ratings and reviews of each product.
  - Code to scrape price, description, and ratings of each products:
```{r}
amazon_products <- function(url) {
  page <- read_html(url)
  
  name <- page %>%
    html_nodes("h2.a-size-mini") %>%
    html_text() 
  
  price <- page %>%
    html_nodes("span.a-price-whole") %>%
    html_text() %>%
    gsub("\\.", "", .) %>%
    as.numeric()
  
  ratings <- page %>%
    html_nodes("span.a-icon-alt") %>%
    html_text() %>%
    gsub(" out of 5 stars", "", .) %>%
    gsub(" Stars & Up", "", .) %>%
    as.numeric()
  
  data.frame(
    Description = name[1:30],
    Price = price[1:30],
    Ratings = ratings[1:30]
  )
}

products <- lapply(urls, amazon_products)
names(products) <- category_df$Category
products[["Backpacks"]]
products[["Laptops"]]
products[["Accessories"]]
products[["Sports"]]
products[["Clothing"]]
```

Code to scrape reviews of each products
```{r}
reviews_scrape <- function(url) {
  page <- read_html(url)
  
  review_link <- page %>%
    html_nodes("a.a-link-normal.s-underline-text.s-underline-link-text.s-link-style.a-text-normal") %>%
    html_attr("href") %>%
    unique() %>%
    paste0("https://www.amazon.com", .)
  
  data.frame(
    review_links = review_link[1:30]
  )
}

review_links_df <- lapply(urls, reviews_scrape)

backpack <- review_links_df[[1]]$review_links
laptops <- review_links_df[[2]]$review_links
accessories <- review_links_df[[3]]$review_links
sports <- review_links_df[[4]]$review_links
clothing <- review_links_df[[5]]$review_links

reviews_text <- function(urls) {
  
  results <- data.frame(
    Reviews = character(length(urls)),  
    stringsAsFactors = FALSE
  )
  
  # loop through each URL
  for (i in seq_along(urls)) {
    if (is.na(urls[i])) {
      results$Reviews[i] <- NA
    } else {
      # scrape reviews
      page <- read_html(urls[i])
      reviews_data <- page %>%
        html_nodes("p.a-spacing-small") %>%
        .[1] %>%
        html_text()

      results$Reviews[i] <- if (length(reviews_data) > 0) reviews_data else NA
    }
  }
  
  return(results)
}

backpack_reviews <- reviews_text(backpack)
laptop_reviews <- reviews_text(laptops)
accessories_reviews <- reviews_text(accessories)
sports_reviews <- reviews_text(sports)
clothing_reviews <- reviews_text(clothing)
```

Complete Data Frame of price, description, ratings and reviews of each product.
```{r}
backpack_category <- cbind(products[["Backpacks"]], backpack_reviews)
laptop_category <- cbind(products[["Laptops"]], laptop_reviews)
accessories_category <- cbind(products[["Accessories"]], accessories_reviews)
sports_category <- cbind(products[["Sports"]], sports_reviews)
clothing_category <- cbind(products[["Clothing"]], clothing_reviews)

```

6. Describe the data you have extracted.
##### START #####

The extracted data consists of information from the five  categories we have selected  from Amazon. These include: Backpacks, Laptops, Accessories, Sports, and Clothing. For each category, 30 products were selected, resulting in a total of 150 products with details including price, description, ratings, and reviews for each product.

##### END #####


7. What will be your use case for the data you have extracted?
##### START #####

If we use the extracted data, we can aim to evaluate the value for money offered by different product categories based on their average rating and average price. By calculating the rating-to-price ratio for each category, we can identify which categories provide the best perceived quality relative to their cost. 

##### END #####


8. Create graphs regarding the use case, and briefly explain it.
```{r}
#function to get rating to price ratio
calculate_ratio <- function(category_df) {
  
  category_df$Ratings[is.na(category_df$Ratings)] <- mean(category_df$Ratings, na.rm = TRUE)
  category_df$Price[is.na(category_df$Price)] <- mean(category_df$Price, na.rm = TRUE)
  
  mean_rating <- mean(category_df$Ratings, na.rm = TRUE)
  mean_price <- mean(category_df$Price, na.rm = TRUE)
  rating_to_price_ratio <- mean_rating / mean_price
  
  list(
    Mean_Rating = mean_rating,
    Mean_Price = mean_price,
    Rating_to_Price_Ratio = rating_to_price_ratio
  )
}

backpack_analysis <- calculate_ratio(backpack_category)
laptop_analysis <- calculate_ratio(laptop_category)
accessories_analysis <- calculate_ratio(accessories_category)
sports_analysis <- calculate_ratio(sports_category)
clothing_analysis <- calculate_ratio(clothing_category)

#combining all the rating to price ratio of all categories
use_case_df <- data.frame(
  Category = c("Backpacks", "Laptops", "Accessories", "Sports", "Clothing"),
  Mean_Rating = c(
    backpack_analysis$Mean_Rating,
    laptop_analysis$Mean_Rating, 
    accessories_analysis$Mean_Rating,
    sports_analysis$Mean_Rating, 
    clothing_analysis$Mean_Rating),
  
  Mean_Price = c(
    backpack_analysis$Mean_Price, 
    laptop_analysis$Mean_Price, 
    accessories_analysis$Mean_Price,
    sports_analysis$Mean_Price, 
    clothing_analysis$Mean_Price),
  
  Rating_to_Price_Ratio = c(
    backpack_analysis$Rating_to_Price_Ratio, 
    laptop_analysis$Rating_to_Price_Ratio, 
    accessories_analysis$Rating_to_Price_Ratio, 
    sports_analysis$Rating_to_Price_Ratio, 
    clothing_analysis$Rating_to_Price_Ratio)
)

print(use_case_df)

```
### Graph for use case ###

The graph allows for easy comparison of how well each category performs in terms of value for money. Categories with taller bars indicate a higher rating-to-price ratio, suggesting better perceived value for money
```{r}
barplot(
  use_case_df$Rating_to_Price_Ratio,
  names.arg = use_case_df$Category,
  main = "Rating to Price Ratio by Category",
  xlab = "Category",
  ylab = "Rating to Price Ratio",
  col =  rainbow(nrow(use_case_df))
)
```


9. Graph the price and the ratings for each category. Use basic plotting functions and ggplot2 package.
```{r}
library(ggplot2)

plot_df <- data.frame(
  Category = rep(
    c("Backpacks", 
      "Laptops",
      "Accessories",
      "Sports",
      "Clothing"),
      each = length(backpack_category$Price)),
  
  Price = c(
    backpack_category$Price, 
    laptop_category$Price, 
    accessories_category$Price, 
    sports_category$Price,
    clothing_category$Price),
  
  Ratings = c(
    backpack_category$Ratings,
    laptop_category$Ratings,
    accessories_category$Ratings,
    sports_category$Ratings, 
    clothing_category$Ratings)
)

# scatterplot using ggplot2
ggplot(combined_df, aes(x = Price, y = Ratings, color = Category)) +
  geom_point(size = 2) + 
  labs(
    title = "Price vs Ratings for Different Categories",
    x = "Price",
    y = "Ratings"
  ) +
  theme_minimal() 
```

10. Rank the products of each category by price and ratings. Explain briefly.
```{r}
library(dplyr)

# Backpacks
backpack_ranked <- backpack_category %>%
  mutate(
    Rank_by_Price = rank(Price, ties.method = "min"),  
    Rank_by_Rating = rank(-Ratings, ties.method = "min")  
  ) %>%
  arrange(Rank_by_Price, Rank_by_Rating)

# Laptops
laptop_ranked <- laptop_category %>%
  mutate(
    Rank_by_Price = rank(Price, ties.method = "min"),
    Rank_by_Rating = rank(-Ratings, ties.method = "min")
  ) %>%
  arrange(Rank_by_Price, Rank_by_Rating)

# Accessories
accessories_ranked <- accessories_category %>%
  mutate(
    Rank_by_Price = rank(Price, ties.method = "min"),
    Rank_by_Rating = rank(-Ratings, ties.method = "min")
  ) %>%
  arrange(Rank_by_Price, Rank_by_Rating)

# Sports
sports_ranked <- sports_category %>%
  mutate(
    Rank_by_Price = rank(Price, ties.method = "min"),
    Rank_by_Rating = rank(-Ratings, ties.method = "min")
  ) %>%
  arrange(Rank_by_Price, Rank_by_Rating)

# Clothing
clothing_ranked <- clothing_category %>%
  mutate(
    Rank_by_Price = rank(Price, ties.method = "min"),
    Rank_by_Rating = rank(-Ratings, ties.method = "min")
  ) %>%
  arrange(Rank_by_Price, Rank_by_Rating)

 print(backpack_ranked)
 print(laptop_ranked)
 print(accessories_ranked)
 print(sports_ranked)
 print(clothing_ranked)
# The data frames displays products grouped by category, showing each product's name and description along with its rank based on price (lower prices get higher ranks) and rating (higher ratings get higher ranks), in the occurence of ties, the higher ranking is prioritized.
 write.csv(backpack_ranked, "BackpackRanking.csv", row.names = FALSE)
 write.csv(laptop_ranked, "LaptopRanking.csv", row.names = FALSE)
 write.csv(accessories_ranked, "AccessoriesRanking.csv", row.names = FALSE)
 write.csv(sports_ranked, "SportsRanking.csv", row.names = FALSE)
 write.csv(clothing_ranked, "ClothingRanking.csv", row.names = FALSE)
```

